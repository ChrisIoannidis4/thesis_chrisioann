{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import SimpleITK as sitk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lists_of_of_paths(directory):\n",
    "    file_list = os.listdir(directory)\n",
    "    file_paths = []\n",
    "    for file in file_list:\n",
    "        file_path = os.path.join(directory, file)\n",
    "        file_paths.append(file_path)\n",
    "\n",
    "    return file_paths  \n",
    "\n",
    "\n",
    "def fn_scan_to_array(base_path):\n",
    "    mid_file=get_lists_of_of_paths(base_path)[0]\n",
    "    slice_list=get_lists_of_of_paths(mid_file)\n",
    "    for i in range(160):\n",
    "        if i==0:    \n",
    "            slice = sitk.ReadImage(get_lists_of_of_paths(mid_file)[0])\n",
    "            scan_array3D = (sitk.GetArrayFromImage(slice)).reshape(384,384)\n",
    "        else:  \n",
    "            slice = sitk.ReadImage(get_lists_of_of_paths(mid_file)[i])\n",
    "            slice_array= sitk.GetArrayFromImage(slice).reshape(384,384)\n",
    "            scan_array3D=np.dstack((scan_array3D, slice_array))\n",
    "    return scan_array3D  # (384, 384, 160)\n",
    "\n",
    "\n",
    "\n",
    "def fn_segm_mask_to_array(subject_name):\n",
    "\n",
    "    mhd_path = \"data/\" + subject_name +\"/\"+subject_name+\".segmentation_masks.mhd\"\n",
    "    segm_mask = sitk.GetArrayFromImage(sitk.ReadImage(mhd_path, sitk.sitkFloat32))\n",
    "    return np.flip(segm_mask, axis=0) # (384, 384, 160)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ChrisIoannidis\\AppData\\Local\\Temp\\ipykernel_31560\\3037991853.py:10: DeprecationWarning: Please use `map_coordinates` from the `scipy.ndimage` namespace, the `scipy.ndimage.interpolation` namespace is deprecated.\n",
      "  from scipy.ndimage.interpolation import map_coordinates\n"
     ]
    }
   ],
   "source": [
    "from utils import getAverageMask, structure_tensor_3D, getGradients\n",
    "from trimesh.creation import icosphere\n",
    "from sklearn.utils.extmath import cartesian\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "import math\n",
    "import itertools\n",
    "from sklearn.preprocessing import normalize\n",
    "from scipy.stats import kurtosis\n",
    "from scipy.special import sph_harm\n",
    "from scipy.ndimage.interpolation import map_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lbp_ri_sh(point, img, patch_size, sph_degree, ico_radius, ico_level, n_bins = 30, concatenate = True):\n",
    "\n",
    "    psize = patch_size // 2\n",
    "    x, y, z = point\n",
    "    patch = img[x - psize - int(math.ceil(ico_radius)) : x + psize + int(math.ceil(ico_radius)) + 1,\n",
    "                y - psize - int(math.ceil(ico_radius)) : y + psize + int(math.ceil(ico_radius)) + 1,\n",
    "                z - psize - int(math.ceil(ico_radius)) : z + psize + int(math.ceil(ico_radius)) + 1]\n",
    "    \n",
    "    patch_coords = cartesian((range(patch_size), range(patch_size), range(patch_size))) + 1    \n",
    "\n",
    "    #construct icosahedron for uniform sampling on sphere surface\n",
    "    ico = icosphere(subdivisions = ico_level, radius = ico_radius)\n",
    "    ico_coords = np.array(ico.vertices)\n",
    "    theta = np.arccos(ico_coords[:, 2] / ico_radius)\n",
    "    phi = np.arctan2(ico_coords[:, 1], ico_coords[:, 0])\n",
    "\n",
    "    #get Spherical Harmonics expansion coefficients (up to degree sph_degree)\n",
    "    m = list(itertools.chain.from_iterable([[i for i in range(-n,n+1)] for n in range(sph_degree)]))\n",
    "    m = np.array(m)\n",
    "\n",
    "    l = list(itertools.chain.from_iterable([[k for _ in range(2 * k + 1)] for k in range(sph_degree)]))\n",
    "    l = np.array(l)\n",
    "\n",
    "    Y = sph_harm(m[None, :], l[None, :], theta[:, None], phi[:, None])\n",
    "\n",
    "    #sample sphere neighbors for each voxel in patch and interpolate intensity\n",
    "    mapped_coords = patch_coords[None, :, :] + ico_coords[:, None, :]\n",
    "    mapped_int = map_coordinates(patch, mapped_coords.T, order = 3)\n",
    "    center_int = patch[ico_radius : -ico_radius, ico_radius : -ico_radius, ico_radius : -ico_radius]\n",
    "\n",
    "    #Compute kurtosis (for better rotation invariance)\n",
    "    kurt = kurtosis(mapped_int)\n",
    "\n",
    "    #Apply sign function and pass obtain spherical expansion coefficients for each sample\n",
    "    f = np.greater_equal(center_int.ravel()[:, None], mapped_int).astype('int')\n",
    "    c = f.dot(Y)\n",
    "\n",
    "    #obtain frequency components of threshold function by integrating and normalizing over orders m\n",
    "    f = np.multiply(c[:, None, l == 0], Y[None, :, l == 0])\n",
    "    for n in range(1, sph_degree):\n",
    "        f = np.concatenate((f, np.sum(np.multiply(c[:, None, l == n], Y[None, :, l == n]),\n",
    "                            axis=2, keepdims=True)), axis=2)\n",
    "    f = np.sqrt(np.sum(f**2, axis=1))\n",
    "\n",
    "    #keep real parts of decomposition and kurtosis\n",
    "    f = np.real(f)\n",
    "    kurt = np.real(kurt)\n",
    "\n",
    "    #extract histograms\n",
    "    H = np.histogram(kurt, bins = n_bins)[0]\n",
    "    for i in range(sph_degree):\n",
    "        H = np.column_stack((H, np.histogram(f[:, i], bins = n_bins)[0]))\n",
    "    H = normalize(H, axis = 0)\n",
    "\n",
    "    #Return Descriptor (concatenated or aggregated histograms)\n",
    "    if concatenate is True:\n",
    "        D = H.T.ravel()\n",
    "    else: \n",
    "        D = H.sum(axis = 1)\n",
    "    D = D / np.linalg.norm(D)\n",
    "\n",
    "    return D\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def hog_3d_proj(point, image, psize = 5, rsize = 15, orientation = 'vertices', level = 1, mode = 'concatenated', \n",
    "                rot_inv = False, norm = 'l2'):\n",
    "    '''\n",
    "    Computes a 3D variant of the HOG Descriptor for an image region centered arounda voxel\n",
    "    The Region of size (rsize x rsize x rsize) is compartmentalized into a set of disjoint patches,\n",
    "    each of size (psize x psize x psize). A histogram of oriented gradients is computed for each patch, \n",
    "    with the orientation bins corresponding to vertices of centers of faces of a regular (refined) icosahedron.\n",
    "    The final descriptor is a weighted aggregate of those histograms. Currently, implementation supports regions arranged in\n",
    "    3x3x3 patches.\n",
    "\n",
    "    Reference: Alexander Klaser, Marcin Marszalek, Cordelia Schmid. \n",
    "               A Spatio-Temporal Descriptor Based on 3D-Gradients. \n",
    "               BMVC 2008 - 19th British Machine Vision Conference, Sep 2008, Leeds, United Kingdom.pp.275:1-10. \n",
    "               DOI:10.5244/C.22.99\n",
    "\n",
    "    ...\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    point : array - like\n",
    "        the voxels to be characterized\n",
    "    image : ndarray\n",
    "        the image containing the voxels\n",
    "    psize : int\n",
    "        size of patches in region\n",
    "    rsize : int\n",
    "        size of region around central voxel\n",
    "    orientation : string\n",
    "        whether to associate histogram bins with vertices of centroids of faces of the icosahedron\n",
    "    ico_coords : string\n",
    "        coordinate system to define icosahedron on\n",
    "    level : int\n",
    "        number of refienement steps for icosahedron\n",
    "    mode : string\n",
    "        chooses whether to concatenate or aggregate patch histograms to form final descriptor\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    D : ndarray\n",
    "        voxel descriptor\n",
    "\n",
    "    '''\n",
    "\n",
    "    #sanity check\n",
    "    assert type(rsize // psize) == int, print(\"Wrong combination of regional and patch sizes\")\n",
    "\n",
    "    #set params\n",
    "    rs = rsize // 2\n",
    "    ps = psize // 2\n",
    "    ncells = rsize // psize\n",
    "    \n",
    "    # get icosahedron\n",
    "    ico = icosphere(subdivisions = level)\n",
    "    if orientation  == 'faces':\n",
    "        axes = np.array(ico.face_normals)\n",
    "    else:\n",
    "        axes = np.array(ico.vertices)\n",
    "\n",
    "    # get average masks\n",
    "    region_mask = getAverageMask(rsize // psize, 'manhattan')\n",
    "    patch_mask = getAverageMask(psize, 'manhattan')\n",
    "\n",
    "    #calculate partial derivatives\n",
    "    x, y, z = point \n",
    "    xp = range(- rs + ps, rs - ps + 1, psize)\n",
    "    yp = range(- rs + ps, rs - ps + 1, psize)\n",
    "    zp = range(- rs + ps, rs - ps + 1, psize)\n",
    "    patch_centers = cartesian((xp, yp, zp))\n",
    "    patch_locations = patch_centers + psize\n",
    "\n",
    "    # extracting +1 voxel in each direction for computational consistency\n",
    "    region = image[x - rs - 1 : x + rs + 2,\n",
    "                   y - rs - 1 : y + rs + 2,\n",
    "                   z - rs - 1 : z + rs + 2]\n",
    "        \n",
    "    i_dx, i_dy, i_dz = getGradients(region)\n",
    "\n",
    "    #get gradients at the patch level\n",
    "    dx = np.array([i_dx[ploc[0] : ploc[0] + psize, ploc[1] : ploc[1] + psize,\n",
    "                        ploc[2] : ploc[2] + psize] for ploc in patch_locations])\n",
    "\n",
    "    dy = np.array([i_dy[ploc[0] : ploc[0] + psize, ploc[1] : ploc[1] + psize,\n",
    "                        ploc[2] : ploc[2] + psize] for ploc in patch_locations])\n",
    "    \n",
    "    dz = np.array([i_dz[ploc[0] : ploc[0] + psize, ploc[1] : ploc[1] + psize,\n",
    "                        ploc[2] : ploc[2] + psize] for ploc in patch_locations])\n",
    "\n",
    "    dx = dx.reshape((ncells**3, psize**3))\n",
    "    dy = dy.reshape((ncells**3, psize**3))\n",
    "    dz = dz.reshape((ncells**3, psize**3))\n",
    "\n",
    "    #collect all gradients in one array and calculate magnitudes\n",
    "    raw_gradients = np.dstack((dx, dy, dz))\n",
    "    if rot_inv is True:\n",
    "        #rotate region according to dominant direction to achieve rotational invariance\n",
    "        R = structure_tensor_3D(raw_gradients, getAverageMask(rsize, 'gaussian'))\n",
    "        gradients = R.T.dot(raw_gradients.reshape((-1, 3)).T) \n",
    "        gradients = gradients.reshape(3, raw_gradients.shape[1], raw_gradients.shape[0]).T\n",
    "    else:\n",
    "        gradients = raw_gradients\n",
    "    gradient_magnitudes = np.linalg.norm(gradients, axis = 2)\n",
    "\n",
    "    #project gradients to icosahedron orientation axes\n",
    "    projected_gradients = gradients.dot(axes.T)\n",
    "    projected_gradients /= (gradient_magnitudes[:, :, None]+0.001)\n",
    "\n",
    "    # compute theshold to clip projected gradients and recalculate magnitude\n",
    "    inner_prods = linear_kernel(axes)[0, :]\n",
    "    thres = np.sort(inner_prods)[-2]\n",
    "\n",
    "    projected_gradients -= thres\n",
    "    projected_gradients[projected_gradients < 0] = 0\n",
    "    projected_gradient_magnitudes = np.linalg.norm(projected_gradients, axis = 2)\n",
    "\n",
    "    #distribute original magnitude in orientation bins\n",
    "    gradient_histograms = projected_gradients * (gradient_magnitudes[:, :, None] / (projected_gradient_magnitudes[:, :, None]+0.001))\n",
    "    D = gradient_histograms.sum(axis = 1)\n",
    "\n",
    "    if mode == 'flatten':\n",
    "        Descriptor = (region_mask.ravel()[:, None] * D).ravel()\n",
    "    else:\n",
    "        Descriptor = region_mask.ravel().dot(D)\n",
    "\n",
    "    if norm == 'l2':\n",
    "        Descriptor = Descriptor / np.linalg.norm(Descriptor)\n",
    "    if norm == 'l2-hys':\n",
    "        Descriptor = Descriptor / np.linalg.norm(Descriptor)\n",
    "        Descriptor = np.clip(Descriptor, a_min = 0, a_max = 0.25)\n",
    "        Descriptor = Descriptor / np.linalg.norm(Descriptor)\n",
    "    \n",
    "    return Descriptor\n",
    "   \n",
    "\n",
    "def fn_hog_lbp_descriptor(coordinate, array):  \n",
    "    descriptor_lbp = lbp_ri_sh(coordinate, array, 5, 4, 2, 2, concatenate = True)\n",
    "    descriptor_hog = hog_3d_proj(coordinate, array) \n",
    "    descriptor_lbp_hog = np.concatenate([descriptor_hog,descriptor_lbp])\n",
    "    return descriptor_lbp_hog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "codewords = np.load('codewords.npy')\n",
    "mri_scan = fn_scan_to_array('data/9001104')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "subregion_descriptors = []\n",
    "for coordinate in np.load('coordinates/sub_3_coord.npy'):\n",
    "    subregion_descriptors.append(np.array(fn_hog_lbp_descriptor(coordinate, mri_scan)))\n",
    "\n",
    "subregion_descriptors = np.array(subregion_descriptors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def soft_assign_histogram(codewords, subregion_descriptors, a = 5):\n",
    "    histogram = np.zeros(codewords.shape[0])\n",
    "    for j, descriptor in enumerate(subregion_descriptors):\n",
    "        descriptor_assignment=np.empty([1,codewords.shape[0]])\n",
    "        for i, word in enumerate(codewords):\n",
    "            diff = np.linalg.norm(descriptor-word)**2\n",
    "            descriptor_assignment[0][i] = np.exp(- a * diff)\n",
    "        descriptor_assignment = descriptor_assignment/np.sum(descriptor_assignment)    \n",
    "        histogram+=descriptor_assignment.reshape(descriptor_assignment.shape[1])\n",
    "    histogram/=np.sum(histogram)\n",
    "\n",
    "    return histogram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram = soft_assign_histogram(codewords, subregion_descriptors, a = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225\n"
     ]
    }
   ],
   "source": [
    "for subregion in os.listdir('coordinates'):\n",
    "    if 'sub_1' in subregion:\n",
    "        subregion = np.load('coordinates/'+subregion)\n",
    "        print(np.max(subregion.T[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "codewords = np.load('codewords.npy')\n",
    "\n",
    "\n",
    "def create_global_Descriptor(scan_array):\n",
    "    subregion_descriptor_list = []\n",
    "    for subregion in os.listdir('coordinates'):\n",
    "        if 'sub' in subregion:\n",
    "            subregion_coordinates = np.load('coordinates/' + subregion)\n",
    "            subregion_descriptors = []\n",
    "            for i,coordinate in enumerate(subregion_coordinates):\n",
    "                subregion_descriptors.append(np.array(fn_hog_lbp_descriptor(coordinate, scan_array)))\n",
    "                if i%500 == 0 : \n",
    "                    print(str((i*100)/subregion_coordinates.shape[0]) , \"%\")\n",
    "            subregion_descriptors = np.array(subregion_descriptors)\n",
    "            histogram = soft_assign_histogram(codewords, subregion_descriptors, a = 0.4)   \n",
    "            subregion_descriptor_list.append(histogram)\n",
    "            \n",
    "    global_descriptor = np.concatenate([subregion_descriptors[i] for i in range(len(subregion_descriptors))])\n",
    "    global_descriptor/=3\n",
    "    \n",
    "    \n",
    "    return global_descriptor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for scan_no in os.listdir('data'):\n",
    "    if scan_no not in ['9001104','9002430','9002817','9003430','9006723','9004175','9005075','9005132', '9011115']:\n",
    "        print(scan_no)\n",
    "        try:\n",
    "            scan_array=fn_scan_to_array('data/'+scan_no)\n",
    "            global_descriptor = create_global_Descriptor(scan_array)\n",
    "            np.save(\"global_descriptors/gd_\"+scan_no, global_descriptor)\n",
    "        except RuntimeError:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1932096,) 0.22462752090180113 0.0 [0.         0.08565949 0.         ... 0.04915392 0.04915392 0.02184618]\n"
     ]
    }
   ],
   "source": [
    "print(global_descriptor.shape, \n",
    "    np.max(global_descriptor), np.min(global_descriptor),\n",
    "    global_descriptor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
