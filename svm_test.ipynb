{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ChrisIoannidis\\AppData\\Local\\Temp\\ipykernel_29788\\3960403388.py:13: DeprecationWarning: Please use `map_coordinates` from the `scipy.ndimage` namespace, the `scipy.ndimage.interpolation` namespace is deprecated.\n",
      "  from scipy.ndimage.interpolation import map_coordinates\n"
     ]
    }
   ],
   "source": [
    "import SimpleITK as sitk\n",
    "import os\n",
    "import numpy as np\n",
    "from utils import getAverageMask, structure_tensor_3D, getGradients\n",
    "from trimesh.creation import icosphere\n",
    "from sklearn.utils.extmath import cartesian\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "import math\n",
    "import itertools\n",
    "from sklearn.preprocessing import normalize\n",
    "from scipy.stats import kurtosis\n",
    "from scipy.special import sph_harm\n",
    "from scipy.ndimage.interpolation import map_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinate_cube = np.load('coordinates/coordinate_cube.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lists_of_of_paths(directory):\n",
    "    file_list = os.listdir(directory)\n",
    "    file_paths = []\n",
    "    for file in file_list:\n",
    "        file_path = os.path.join(directory, file)\n",
    "        file_paths.append(file_path)\n",
    "\n",
    "    return file_paths  \n",
    "\n",
    "\n",
    "def svm_coordinate_sampling(segm, roi):\n",
    "    coord_labels = []\n",
    "    coordinates = []\n",
    "    \n",
    "    mask_values = segm[coordinate_cube[:,0], coordinate_cube[:,1], coordinate_cube[:,2]]\n",
    "\n",
    "    threshold_4 = np.count_nonzero(mask_values == 4) #.shape[0]#len(segm[segm[coordinate_cube]==4])\n",
    "    \n",
    "    threshold_1=int(threshold_4/1.3)\n",
    "    threshold_2=int(threshold_4*1.3)\n",
    "    threshold_3=int(threshold_4/1.3)\n",
    "    threshold_0=int(threshold_4/1.4)\n",
    "   \n",
    "    i_0,i_1,i_2,i_3,i_4 =0, 0, 0, 0, 0\n",
    "    \n",
    "    print(threshold_0,threshold_1,threshold_2,threshold_3,threshold_4)\n",
    "        \n",
    "        \n",
    "    for coordinate in coordinate_cube:\n",
    "        x,y,z = coordinate\n",
    "        if roi[x,y,z]==1 and 360>x>6 and 360>y>6 and 150>z>6:\n",
    "            if segm[x,y,z]==0 and i_0<threshold_0:\n",
    "                coordinates.append(coordinate)\n",
    "                i_0+=1\n",
    "                coord_labels.append(0)\n",
    "            elif segm[x,y,z]==1 and i_1<threshold_1:\n",
    "                coordinates.append(coordinate)\n",
    "                i_1+=1\n",
    "                coord_labels.append(1)\n",
    "            elif segm[x,y,z]==2 and i_2<threshold_2:\n",
    "                coordinates.append(coordinate)\n",
    "                i_2+=1\n",
    "                coord_labels.append(2)\n",
    "            elif segm[x,y,z]==3 and i_3<threshold_3:\n",
    "                coordinates.append(coordinate)\n",
    "                i_3+=1\n",
    "                coord_labels.append(3)\n",
    "            elif segm[x,y,z]==4 and i_4<threshold_4:\n",
    "                coordinates.append(coordinate)\n",
    "                i_4+=1 \n",
    "                coord_labels.append(4)\n",
    "                \n",
    "    coord_labels=np.array(coord_labels)\n",
    "    unique_values, counts = np.unique(coord_labels, return_counts=True)\n",
    "\n",
    "    for value, count in zip(unique_values, counts):\n",
    "        print(f\"{value}: {count}\")\n",
    "    coordinates = np.array(coordinates)  \n",
    "    np.random.shuffle(coordinates)      \n",
    "    return coordinates\n",
    "\n",
    "\n",
    "\n",
    "def fn_scan_to_array(base_path):\n",
    "    mid_file=get_lists_of_of_paths(base_path)[0]\n",
    "    slice_list=get_lists_of_of_paths(mid_file)\n",
    "    for i in range(160):\n",
    "        if i==0:    \n",
    "            slice = sitk.ReadImage(get_lists_of_of_paths(mid_file)[0])\n",
    "            scan_array3D = (sitk.GetArrayFromImage(slice)).reshape(384,384)\n",
    "        else:  \n",
    "            slice = sitk.ReadImage(get_lists_of_of_paths(mid_file)[i])\n",
    "            slice_array= sitk.GetArrayFromImage(slice).reshape(384,384)\n",
    "            scan_array3D=np.dstack((scan_array3D, slice_array))\n",
    "    return scan_array3D  # (384, 384, 160)\n",
    "\n",
    "\n",
    "\n",
    "def fn_segm_mask_to_array(subject_name):\n",
    "\n",
    "    mhd_path = \"data/\" + subject_name +\"/\"+subject_name+\".segmentation_masks.mhd\"\n",
    "    segm_mask = sitk.GetArrayFromImage(sitk.ReadImage(mhd_path, sitk.sitkFloat32))\n",
    "    return np.flip(segm_mask, axis=0) # (384, 384, 160)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1851 1993 3369 1993 2592\n",
      "0: 1851\n",
      "1: 1993\n",
      "2: 3369\n",
      "3: 1993\n",
      "4: 2592\n"
     ]
    }
   ],
   "source": [
    "mri_scan = fn_scan_to_array('data/9004175')\n",
    "segm_mask = fn_segm_mask_to_array('9004175')\n",
    "roi = np.load('data/9004175/roi.npy')\n",
    "coordinates = svm_coordinate_sampling(segm_mask, roi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lbp_ri_sh(point, img, patch_size, sph_degree, ico_radius, ico_level, n_bins = 30, concatenate = True):\n",
    "    '''\n",
    "    Computes a 3D LBP texture descriptor for a region centered around a voxel. The intensity values \n",
    "    of the neighboring voxels is treated as a spherical function, and decomposed into a sum of\n",
    "    spherical harmonics, achieving rotational invariance. A histogram of the texture codes is computed for\n",
    "    each frequency (band) and the final descriptor is the concatenation of the above histograms.\n",
    "\n",
    "    Reference : 3D LBP-Based Rotationally Invariant Region Description, \n",
    "                Banerjee J., Moelker A., Niessen W., Walsum  v. T., \n",
    "                ACCV 2012 Workshops, Part I, LNCS 7728, pp. 26-37, 2013\n",
    "\n",
    "    ...\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    point : tuple\n",
    "        the point to be described\n",
    "    img : ndarray (width x height x depth)\n",
    "        the MR image\n",
    "    patch_size : int\n",
    "        size of cellular patch around point\n",
    "    sph_degree : int\n",
    "        degree up to which to expand to spherical harmonics\n",
    "    ico_radius : float\n",
    "        radius of icosahedron to uniformly sample intensities around patch voxels\n",
    "    ico_level : int\n",
    "        controls refinement level of icosahedron\n",
    "    n_bins : int\n",
    "        number of bins for LBP histograms\n",
    "    concatenate : bool\n",
    "        if true, concatenate histograms, otherwise weighted aggregation\n",
    "\n",
    "    Returns\n",
    "    ------- \n",
    "    D : ndarray \n",
    "        LBP descriptor\n",
    "\n",
    "    '''\n",
    "\n",
    "    #extract image patch\n",
    "    psize = patch_size // 2\n",
    "    x, y, z = point\n",
    "    patch = img[x - psize - int(math.ceil(ico_radius)) : x + psize + int(math.ceil(ico_radius)) + 1,\n",
    "                y - psize - int(math.ceil(ico_radius)) : y + psize + int(math.ceil(ico_radius)) + 1,\n",
    "                z - psize - int(math.ceil(ico_radius)) : z + psize + int(math.ceil(ico_radius)) + 1]\n",
    "    \n",
    "    patch_coords = cartesian((range(patch_size), range(patch_size), range(patch_size))) + 1    \n",
    "\n",
    "    #construct icosahedron for uniform sampling on sphere surface\n",
    "    ico = icosphere(subdivisions = ico_level, radius = ico_radius)\n",
    "    ico_coords = np.array(ico.vertices)\n",
    "    theta = np.arccos(ico_coords[:, 2] / ico_radius)\n",
    "    phi = np.arctan2(ico_coords[:, 1], ico_coords[:, 0])\n",
    "\n",
    "    #get Spherical Harmonics expansion coefficients (up to degree sph_degree)\n",
    "    m = list(itertools.chain.from_iterable([[i for i in range(-n,n+1)] for n in range(sph_degree)]))\n",
    "    m = np.array(m)\n",
    "\n",
    "    l = list(itertools.chain.from_iterable([[k for _ in range(2 * k + 1)] for k in range(sph_degree)]))\n",
    "    l = np.array(l)\n",
    "\n",
    "    Y = sph_harm(m[None, :], l[None, :], theta[:, None], phi[:, None])\n",
    "\n",
    "    #sample sphere neighbors for each voxel in patch and interpolate intensity\n",
    "    mapped_coords = patch_coords[None, :, :] + ico_coords[:, None, :]\n",
    "    mapped_int = map_coordinates(patch, mapped_coords.T, order = 3)\n",
    "    center_int = patch[ico_radius : -ico_radius, ico_radius : -ico_radius, ico_radius : -ico_radius]\n",
    "\n",
    "    #Compute kurtosis (for better rotation invariance)\n",
    "    kurt = kurtosis(mapped_int)\n",
    "\n",
    "    #Apply sign function and pass obtain spherical expansion coefficients for each sample\n",
    "    f = np.greater_equal(center_int.ravel()[:, None], mapped_int).astype('int')\n",
    "    c = f.dot(Y)\n",
    "\n",
    "    #obtain frequency components of threshold function by integrating and normalizing over orders m\n",
    "    f = np.multiply(c[:, None, l == 0], Y[None, :, l == 0])\n",
    "    for n in range(1, sph_degree):\n",
    "        f = np.concatenate((f, np.sum(np.multiply(c[:, None, l == n], Y[None, :, l == n]),\n",
    "                            axis=2, keepdims=True)), axis=2)\n",
    "    f = np.sqrt(np.sum(f**2, axis=1))\n",
    "\n",
    "    #keep real parts of decomposition and kurtosis\n",
    "    f = np.real(f)\n",
    "    kurt = np.real(kurt)\n",
    "\n",
    "    #extract histograms\n",
    "    H = np.histogram(kurt, bins = n_bins)[0]\n",
    "    for i in range(sph_degree):\n",
    "        H = np.column_stack((H, np.histogram(f[:, i], bins = n_bins)[0]))\n",
    "    H = normalize(H, axis = 0)\n",
    "\n",
    "    #Return Descriptor (concatenated or aggregated histograms)\n",
    "    if concatenate is True:\n",
    "        D = H.T.ravel()\n",
    "    else: \n",
    "        D = H.sum(axis = 1)\n",
    "    D = D / np.linalg.norm(D)\n",
    "\n",
    "    return D\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def hog_3d_proj(point, image, psize = 5, rsize = 15, orientation = 'vertices', level = 1, mode = 'concatenated', \n",
    "                rot_inv = False, norm = 'l2'):\n",
    "    '''\n",
    "    Computes a 3D variant of the HOG Descriptor for an image region centered arounda voxel\n",
    "    The Region of size (rsize x rsize x rsize) is compartmentalized into a set of disjoint patches,\n",
    "    each of size (psize x psize x psize). A histogram of oriented gradients is computed for each patch, \n",
    "    with the orientation bins corresponding to vertices of centers of faces of a regular (refined) icosahedron.\n",
    "    The final descriptor is a weighted aggregate of those histograms. Currently, implementation supports regions arranged in\n",
    "    3x3x3 patches.\n",
    "\n",
    "    Reference: Alexander Klaser, Marcin Marszalek, Cordelia Schmid. \n",
    "               A Spatio-Temporal Descriptor Based on 3D-Gradients. \n",
    "               BMVC 2008 - 19th British Machine Vision Conference, Sep 2008, Leeds, United Kingdom.pp.275:1-10. \n",
    "               DOI:10.5244/C.22.99\n",
    "\n",
    "    ...\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    point : array - like\n",
    "        the voxels to be characterized\n",
    "    image : ndarray\n",
    "        the image containing the voxels\n",
    "    psize : int\n",
    "        size of patches in region\n",
    "    rsize : int\n",
    "        size of region around central voxel\n",
    "    orientation : string\n",
    "        whether to associate histogram bins with vertices of centroids of faces of the icosahedron\n",
    "    ico_coords : string\n",
    "        coordinate system to define icosahedron on\n",
    "    level : int\n",
    "        number of refienement steps for icosahedron\n",
    "    mode : string\n",
    "        chooses whether to concatenate or aggregate patch histograms to form final descriptor\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    D : ndarray\n",
    "        voxel descriptor\n",
    "\n",
    "    '''\n",
    "\n",
    "    #sanity check\n",
    "    assert type(rsize // psize) == int, print(\"Wrong combination of regional and patch sizes\")\n",
    "\n",
    "    #set params\n",
    "    rs = rsize // 2\n",
    "    ps = psize // 2\n",
    "    ncells = rsize // psize\n",
    "    \n",
    "    # get icosahedron\n",
    "    ico = icosphere(subdivisions = level)\n",
    "    if orientation  == 'faces':\n",
    "        axes = np.array(ico.face_normals)\n",
    "    else:\n",
    "        axes = np.array(ico.vertices)\n",
    "\n",
    "    # get average masks\n",
    "    region_mask = getAverageMask(rsize // psize, 'manhattan')\n",
    "    patch_mask = getAverageMask(psize, 'manhattan')\n",
    "\n",
    "    #calculate partial derivatives\n",
    "    x, y, z = point \n",
    "    xp = range(- rs + ps, rs - ps + 1, psize)\n",
    "    yp = range(- rs + ps, rs - ps + 1, psize)\n",
    "    zp = range(- rs + ps, rs - ps + 1, psize)\n",
    "    patch_centers = cartesian((xp, yp, zp))\n",
    "    patch_locations = patch_centers + psize\n",
    "\n",
    "    # extracting +1 voxel in each direction for computational consistency\n",
    "    region = image[x - rs - 1 : x + rs + 2,\n",
    "                   y - rs - 1 : y + rs + 2,\n",
    "                   z - rs - 1 : z + rs + 2]\n",
    "        \n",
    "    i_dx, i_dy, i_dz = getGradients(region)\n",
    "\n",
    "    #get gradients at the patch level\n",
    "    dx = np.array([i_dx[ploc[0] : ploc[0] + psize, ploc[1] : ploc[1] + psize,\n",
    "                        ploc[2] : ploc[2] + psize] for ploc in patch_locations])\n",
    "\n",
    "    dy = np.array([i_dy[ploc[0] : ploc[0] + psize, ploc[1] : ploc[1] + psize,\n",
    "                        ploc[2] : ploc[2] + psize] for ploc in patch_locations])\n",
    "    \n",
    "    dz = np.array([i_dz[ploc[0] : ploc[0] + psize, ploc[1] : ploc[1] + psize,\n",
    "                        ploc[2] : ploc[2] + psize] for ploc in patch_locations])\n",
    "\n",
    "    dx = dx.reshape((ncells**3, psize**3))\n",
    "    dy = dy.reshape((ncells**3, psize**3))\n",
    "    dz = dz.reshape((ncells**3, psize**3))\n",
    "\n",
    "    #collect all gradients in one array and calculate magnitudes\n",
    "    raw_gradients = np.dstack((dx, dy, dz))\n",
    "    if rot_inv is True:\n",
    "        #rotate region according to dominant direction to achieve rotational invariance\n",
    "        R = structure_tensor_3D(raw_gradients, getAverageMask(rsize, 'gaussian'))\n",
    "        gradients = R.T.dot(raw_gradients.reshape((-1, 3)).T) \n",
    "        gradients = gradients.reshape(3, raw_gradients.shape[1], raw_gradients.shape[0]).T\n",
    "    else:\n",
    "        gradients = raw_gradients\n",
    "    gradient_magnitudes = np.linalg.norm(gradients, axis = 2)\n",
    "\n",
    "    #project gradients to icosahedron orientation axes\n",
    "    projected_gradients = gradients.dot(axes.T)\n",
    "    projected_gradients /= (gradient_magnitudes[:, :, None]+0.001)\n",
    "\n",
    "    # compute theshold to clip projected gradients and recalculate magnitude\n",
    "    inner_prods = linear_kernel(axes)[0, :]\n",
    "    thres = np.sort(inner_prods)[-2]\n",
    "\n",
    "    projected_gradients -= thres\n",
    "    projected_gradients[projected_gradients < 0] = 0\n",
    "    projected_gradient_magnitudes = np.linalg.norm(projected_gradients, axis = 2)\n",
    "\n",
    "    #distribute original magnitude in orientation bins\n",
    "    gradient_histograms = projected_gradients * (gradient_magnitudes[:, :, None] / (projected_gradient_magnitudes[:, :, None]+0.001))\n",
    "    D = gradient_histograms.sum(axis = 1)\n",
    "\n",
    "    if mode == 'flatten':\n",
    "        Descriptor = (region_mask.ravel()[:, None] * D).ravel()\n",
    "    else:\n",
    "        Descriptor = region_mask.ravel().dot(D)\n",
    "\n",
    "    if norm == 'l2':\n",
    "        Descriptor = Descriptor / np.linalg.norm(Descriptor)\n",
    "    if norm == 'l2-hys':\n",
    "        Descriptor = Descriptor / np.linalg.norm(Descriptor)\n",
    "        Descriptor = np.clip(Descriptor, a_min = 0, a_max = 0.25)\n",
    "        Descriptor = Descriptor / np.linalg.norm(Descriptor)\n",
    "    \n",
    "    return Descriptor\n",
    "   \n",
    "\n",
    "def fn_hog_lbp_descriptor(coordinate, array):  \n",
    "    descriptor_lbp = lbp_ri_sh(coordinate, array, 5, 4, 2, 2, concatenate = True)\n",
    "    descriptor_hog = hog_3d_proj(coordinate, array) \n",
    "    descriptor_lbp_hog = np.concatenate([descriptor_hog,descriptor_lbp])\n",
    "    return descriptor_lbp_hog.reshape(1, len(descriptor_lbp_hog))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(192,)\n",
      "created datasets\n",
      "(9438, 192) (9438,)\n",
      "fitting model\n",
      "Accuracy: 0.8440677966101695\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Step 3: Prepare the data for SVM training\n",
    "descriptors = []\n",
    "labels = []\n",
    "for coord in coordinates:\n",
    "    descriptor = fn_hog_lbp_descriptor(coord, mri_scan)\n",
    "    # if descriptor!= None # makeshiftSIFT(mri_scan, coord)\n",
    "    descriptor = np.reshape(descriptor, [descriptor.shape[1],])\n",
    "    descriptors.append(descriptor)\n",
    "    value = segm_mask[coord[0], coord[1], coord[2]]\n",
    "    if value == 0:\n",
    "        labels.append(0)\n",
    "    elif value == 1 or value == 3:\n",
    "        labels.append(1)\n",
    "    elif value == 2 or value == 4:\n",
    "        labels.append(2)\n",
    "    else:\n",
    "        labels.append(value)   \n",
    "    \n",
    "    if len(descriptors) == 1:\n",
    "        print(descriptor.shape)\n",
    "    # labels.append(value)\n",
    "    \n",
    "    \n",
    "X = np.array(descriptors)\n",
    "y = np.array(labels)\n",
    "\n",
    "print('created datasets')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train.shape, y_train.shape )\n",
    "# Step 4: Train the SVM\n",
    "svm = SVC(kernel= 'linear', decision_function_shape ='ovr')\n",
    "print('fitting model')\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Step 5: Predict on the test set\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "# Step 6: Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.65      0.69       363\n",
      "           1       0.86      0.88      0.87       808\n",
      "           2       0.86      0.88      0.87      1189\n",
      "\n",
      "    accuracy                           0.84      2360\n",
      "   macro avg       0.82      0.80      0.81      2360\n",
      "weighted avg       0.84      0.84      0.84      2360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true 1.0\n",
      "pred_1 [1]\n",
      "Predicted class: 2\n"
     ]
    }
   ],
   "source": [
    "coord = coordinates[1500]\n",
    "descriptor = fn_hog_lbp_descriptor(coord, mri_scan)\n",
    "\n",
    "value = segm_mask[coord[0], coord[1], coord[2]]\n",
    "\n",
    "print(\"true\", value)\n",
    "print(\"pred_1\", svm.predict(descriptor))\n",
    "descriptor =descriptor.reshape(192,)\n",
    "decision_value = np.dot(descriptor, svm.coef_.T ) + svm.intercept_\n",
    "predicted_class = decision_value.argmax()\n",
    "\n",
    "print(\"Predicted class:\", predicted_class)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
