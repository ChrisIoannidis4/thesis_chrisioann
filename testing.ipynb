{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5671, 3)\n",
      "(2000, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import random\n",
    "import numpy as np\n",
    "def select_subset(array, subset_size):\n",
    "    subset_indices = random.sample(range(len(array)), subset_size)\n",
    "    subset = [array[i] for i in subset_indices]\n",
    "    return np.array(subset)\n",
    "origial_array=np.load('data/temp/sampled_coordinates.npy')\n",
    "print(origial_array.shape)\n",
    "coord_subset = select_subset(origial_array, 2000)\n",
    "print(coord_subset.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(640, 438)\n"
     ]
    }
   ],
   "source": [
    "from functions.c_optimization_problem import initialize_dictionary\n",
    "import numpy as np\n",
    "\n",
    "Weight_Space = np.load(\"data/X_W_arrays/W_space.npy\")\n",
    "\n",
    "print(Weight_Space.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dw = initialize_dictionary(Weight_Space, 20)\n",
    "print(Dw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(640, 20)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def initialize_coefficients(D, all_ellements, a):\n",
    "    #X: (150, 500), d: (150X25), a: soothing factor\n",
    "    coefficients=np.zeros((D.shape[1] , all_ellements.shape[1]))\n",
    "    \n",
    "    for j, sample in enumerate(all_ellements.T):\n",
    "        for i, word in enumerate(D.T):\n",
    "            diff = np.linalg.norm(sample-word)**2\n",
    "            c_1=np.exp(-a * diff)\n",
    "            coefficients[i][j]=c_1\n",
    "    coefficients[:,j]/=np.sum(coefficients[:,j])\n",
    "    return coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions.c_optimization_problem import initialize_coefficients\n",
    "\n",
    "Lw=initialize_coefficients(Dw, Weight_Space, 0.2)\n",
    "print(Lw.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"data/dictionaries/Dw\", Weight_Space)\n",
    "np.save(\"data/dictionaries/Lw\", Lw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1] (384, 384, 160)\n",
      "(20481580, 3)\n"
     ]
    }
   ],
   "source": [
    "def load_roi(subj_no):\n",
    "    roi = np.load(\"data/MRI_MASKS/roi_masks_dataset/roi_\"+ subj_no + \".npy\")\n",
    "    return roi \n",
    "\n",
    "roi = load_roi(\"9002430\")\n",
    "print(np.unique(roi), roi.shape)\n",
    "\n",
    "\n",
    "def gather_roi_indices(roi_array):\n",
    "    roi_inices=np.array(np.where(roi_array == 1)).T\n",
    "    # print(roi_inices)\n",
    "    roi_perimeter= [np.array(coord) for coord in roi_inices]\n",
    "    return np.array(roi_perimeter)\n",
    "# roi_perimeter=gather_roi_indices(roi)\n",
    "# print(roi_perimeter.shape, roi_perimeter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save(\"data/temp/roi_perimeter\", roi_perimeter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roi_perimeter = np.load(\"data/temp/roi_perimeter.npy\")\n",
    "from sklearn.cluster import KMeans \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KMeans(n_clusters=120, random_state=1, verbose=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KMeans</label><div class=\"sk-toggleable__content\"><pre>KMeans(n_clusters=120, random_state=1, verbose=False)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KMeans(n_clusters=120, random_state=1, verbose=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_state=1\n",
    "kmeans_model1=KMeans(n_clusters=120, verbose=False, init='k-means++', random_state=random_state)\n",
    "kmeans_model1.fit(roi_perimeter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KMeans(n_clusters=5, random_state=1, verbose=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KMeans</label><div class=\"sk-toggleable__content\"><pre>KMeans(n_clusters=5, random_state=1, verbose=False)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KMeans(n_clusters=5, random_state=1, verbose=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans_model2=KMeans(n_clusters=5, verbose=False, init='k-means++', random_state=random_state)\n",
    "kmeans_model2.fit(kmeans_model1.cluster_centers_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[215.70566424, 235.9783591 , 114.44476628],\n",
       "       [219.66768373, 150.40789634,  79.20899779],\n",
       "       [169.9209679 ,  85.58124149,  67.9128662 ],\n",
       "       [210.95772957, 239.71583329,  40.72653948],\n",
       "       [129.37661977, 253.17015378,  81.69693638]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans_model2.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14548, 3)\n"
     ]
    }
   ],
   "source": [
    "roi_subset = []\n",
    "subregion_centers=kmeans_model2.cluster_centers_\n",
    "for coordinate in roi_perimeter:\n",
    "    x,y,z=coordinate\n",
    "    if x%6==0 and y%6==0 and z%6==0:\n",
    "        roi_subset.append(coordinate)\n",
    "roi_subset=np.array(roi_subset)\n",
    "print(roi_subset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_label = kmeans_model1.predict(roi_subset)\n",
    "final_label = kmeans_model2.predict(kmeans_model1.cluster_centers_[first_label])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "subregion_1 = roi_subset[final_label==0]\n",
    "subregion_2 = roi_subset[final_label==1]\n",
    "subregion_3 = roi_subset[final_label==2]\n",
    "subregion_4 = roi_subset[final_label==3]\n",
    "subregion_5 = roi_subset[final_label==4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2725, 3)  --  (3381, 3)  --  (2987, 3)  --  (2658, 3)  --  (2797, 3)\n"
     ]
    }
   ],
   "source": [
    "print(subregion_1.shape, \" -- \", subregion_2.shape, \" -- \",subregion_3.shape, \" -- \",subregion_4.shape, \" -- \",subregion_5.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"data/temp/sub_1_coord.npy\", subregion_1)\n",
    "np.save(\"data/temp/sub_2_coord.npy\", subregion_2)\n",
    "np.save(\"data/temp/sub_3_coord.npy\", subregion_3)\n",
    "np.save(\"data/temp/sub_4_coord.npy\", subregion_4)\n",
    "np.save(\"data/temp/sub_5_coord.npy\", subregion_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates= np.load(\"data/temp/general_coordinates.npy\")\n",
    "dir1 = os.listdir(\"data/MRI_MASKS/subjects\")\n",
    "dir2 = [(os.listdir(\"data/MRI_MASKS/segmentation_masks\")[i]).split(\".\")[0] for i in range(len(os.listdir(\"data/MRI_MASKS/segmentation_masks\")))]\n",
    "dir3 = [(os.listdir(\"data/MRI_MASKS/roi_masks_dataset\")[i]).split(\".\")[0][4:] for i in range(len(os.listdir(\"data/MRI_MASKS/roi_masks_dataset\")))]\n",
    "common_subjects = list(set(dir1).intersection(dir2).intersection(dir3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125, 437) (640, 438)\n"
     ]
    }
   ],
   "source": [
    "X = np.load(\"data/X_W_arrays/X_space.npy\")\n",
    "W = np.load(\"data/X_W_arrays/W_space.npy\")\n",
    "\n",
    "print(X.shape, W.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "437\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "dir1 = os.listdir(\"data/MRI_MASKS/subjects\")\n",
    "dir2 = [(os.listdir(\"data/MRI_MASKS/segmentation_masks\")[i]).split(\".\")[0] for i in range(len(os.listdir(\"data/MRI_MASKS/segmentation_masks\")))]\n",
    "common_subjects = list(set(dir1).intersection(dir2))\n",
    "print(len(common_subjects))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "437\n"
     ]
    }
   ],
   "source": [
    "dir1 = os.listdir(\"data/MRI_MASKS/subjects\")\n",
    "dir2 = [(os.listdir(\"data/MRI_MASKS/segmentation_masks\")[i]).split(\".\")[0] for i in range(len(os.listdir(\"data/MRI_MASKS/segmentation_masks\")))]\n",
    "common_subjects = list(set(dir1).intersection(dir2))\n",
    "print(len(common_subjects))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125, 25)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# print(np.load(\"data/dictionaries/Dw.npy\").shape)\n",
    "Dx = initialize_dictionary(X, 25)\n",
    "print(Dx.shape)\n",
    "np.save(\"data/dictionaries/Dx.npy\",Dx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lx = initialize_coefficients(Dx, X, 0.8) #(25, 437)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"data/dictionaries/Lx.npy\", Lx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from functions.c_optimization_problem import *\n",
    "\n",
    "W = np.load(\"data/X_W_arrays/W_space.npy\")\n",
    "Dw = initialize_dictionary(W, 25)\n",
    "Lw = initialize_coefficients(Dw, W, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"data/dictionaries/W.npy\", W)\n",
    "np.save(\"data/dictionaries/Dw.npy\", Dw)\n",
    "np.save(\"data/dictionaries/LW.npy\", Lw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.07317933345089 %\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "roi1=np.load('data/MRI_MASKS/roi_masks_dataset/roi_9001104.npy')\n",
    "roi2=np.load('data/MRI_MASKS/roi_masks_dataset/roi_9023193.npy')\n",
    "roi3=np.load('data/MRI_MASKS/roi_masks_dataset/roi_9011420.npy')\n",
    "\n",
    "coord=np.load('data/temp/sampled_coordinates.npy')\n",
    "\n",
    "i=0\n",
    "\n",
    "for coordinate in coord:\n",
    "    x,y,z = coordinate\n",
    "    if roi2[x,y,z] ==roi1 [x,y,z] == roi3 [x,y,z]:\n",
    "        i+=1\n",
    "\n",
    "print( i*100 / len(coord) , \"%\" )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING QCQP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_dictionary(all_elements, Dictionary_Size):\n",
    "    \n",
    "    k = Dictionary_Size\n",
    "    descr_kmeans=KMeans(n_clusters=k, random_state=0)\n",
    "    descr_kmeans.fit(all_elements.T)\n",
    "    dictionary = descr_kmeans.cluster_centers_  \n",
    "\n",
    "    return dictionary.T\n",
    "\n",
    "#Soft voting to initialize Lx (Zhang et al 2013 - 2.Soft Assignment Coding)\n",
    "def initialize_coefficients(D, all_ellements, a):\n",
    "    #X: (150, 500), d: (150X25), a: soothing factor\n",
    "    coefficients=np.zeros((D.shape[1] , all_ellements.shape[1]))\n",
    "    \n",
    "    for j, sample in enumerate(all_ellements.T):\n",
    "        for i, word in enumerate(D.T):\n",
    "            diff = np.linalg.norm(sample-word)**2 \n",
    "            c_1=np.exp(-a * diff)\n",
    "            coefficients[i][j]=c_1\n",
    "    coefficients[:,j]/=np.sum(coefficients[:,j])\n",
    "    return coefficients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\MySoftware\\python3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize#, NonlinearConstraint \n",
    "from sklearn.cluster import KMeans \n",
    "# Objective function\n",
    "def objective(dx, X, Lx):\n",
    "    dx =dx.reshape(dx.shape[0],1)\n",
    "    return np.linalg.norm(X - dx @ Lx, ord='fro')#**2\n",
    "\n",
    "# Constraint function\n",
    "def constraint(dx):\n",
    "    return 1 - np.linalg.norm(dx, ord=2)\n",
    "\n",
    "def constraint_jacobian(dx):\n",
    "    return - (dx / np.linalg.norm(dx, ord=2))\n",
    "\n",
    "X = np.random.rand(150, 500)\n",
    "Dx_init = initialize_dictionary(X, 25)\n",
    "Lx = initialize_coefficients(Dx_init, X, 0.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ChrisIoannidis\\AppData\\Local\\Temp\\ipykernel_11496\\2448636275.py:18: DeprecationWarning: Use of `minimize` with `x0.ndim != 1` is deprecated. Currently, singleton dimensions will be removed from `x0`, but an error will be raised in SciPy 1.11.0.\n",
      "  result = minimize(objective, dx_init, args=(A, B), method= 'COBYLA', constraints=[constraint_definition],jac = constraint_jacobian ,options={'maxiter' : 1000 , 'disp' : False })\n",
      "c:\\MySoftware\\python3\\Lib\\site-packages\\scipy\\optimize\\_minimize.py:549: RuntimeWarning: Method COBYLA does not use gradient information (jac).\n",
      "  warn('Method %s does not use gradient information (jac).' % method,\n"
     ]
    }
   ],
   "source": [
    "n = X.shape[1]\n",
    "        \n",
    "        \n",
    "        # Constraint definition\n",
    "constraint_definition = {'type': 'ineq', 'fun': constraint}     \n",
    "\n",
    "def col_by_col_step(Dx_init):\n",
    "\n",
    "    Dx = Dx_init.copy()\n",
    "    \n",
    "    for i, dx_init in enumerate(Dx_init.T):\n",
    "        # Bounds for dx\n",
    "        dx_init = np.reshape(dx_init, [dx_init.shape[0], 1])\n",
    "        # constraint_definition = NonlinearConstraint(constraint, -np.inf, 1, jac=constraint_jacobian)\n",
    "        # objective =  cp.Minimize(cp.sum_squares( + Di@L[i,:].reshape(1,no_samples)))\n",
    "        A = X - np.sum([Dx[:,j].reshape(Dx[:,j].shape[0],1)@Lx[j,:].reshape(1,n) for j in range(Dx.shape[1]) if j!=i], axis=0)\n",
    "        B = Lx[i, :].reshape(1,n)\n",
    "        result = minimize(objective, dx_init, args=(A, B), method= 'COBYLA', constraints=[constraint_definition], options={'maxiter' : 1000 , 'disp' : False })\n",
    "\n",
    "        # Obtained solution\n",
    "        dx_optimal = result.x\n",
    "        \n",
    "        # print(np.linalg.norm(dx_optimal))\n",
    "        Dx[:,i] = dx_optimal\n",
    "\n",
    "    return Dx\n",
    "\n",
    "Dx = col_by_col_step(Dx_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before 157.93763276395114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ChrisIoannidis\\AppData\\Local\\Temp\\ipykernel_11496\\2448636275.py:18: DeprecationWarning: Use of `minimize` with `x0.ndim != 1` is deprecated. Currently, singleton dimensions will be removed from `x0`, but an error will be raised in SciPy 1.11.0.\n",
      "  result = minimize(objective, dx_init, args=(A, B), method= 'COBYLA', constraints=[constraint_definition],jac = constraint_jacobian ,options={'maxiter' : 1000 , 'disp' : False })\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157.93763276395114\n",
      "157.95099537042518\n",
      "157.98538950860853\n",
      "157.982432517066\n",
      "157.98440889237486\n",
      "157.99306041789603\n",
      "157.9745768613824\n",
      "157.98632085643854\n",
      "157.98073586379698\n",
      "157.98531975626346\n"
     ]
    }
   ],
   "source": [
    "def optimization_loop(Dx_init):\n",
    "    norms =[]\n",
    "    Dx = Dx_init.copy()\n",
    "    for i in range(100): \n",
    "        Dx = col_by_col_step(Dx)\n",
    "        print(np.linalg.norm(X - Dx @ Lx, ord='fro'))\n",
    "    return Dx\n",
    "\n",
    "print('before' , np.linalg.norm(X - Dx @ Lx, ord='fro'))\n",
    "\n",
    "\n",
    "Dx = optimization_loop(Dx_init)\n",
    "\n",
    "\n",
    "print('after' , np.linalg.norm(X - Dx @ Lx, ord='fro'))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.1\n"
     ]
    }
   ],
   "source": [
    "import cvxpy as cvx\n",
    "\n",
    "print(cvx.__version__)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxpy as cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def update_dictionaries_step(X, D, L, n, no_samples):\n",
    "    k = 25\n",
    "    # (150x500) = (150x1)(1x500)\n",
    "    for i in range(k):    \n",
    "        Di = cp.Variable((n,1))\n",
    "        # print(\"old: \",D[:10,i])\n",
    "        objective =  cp.Minimize(cp.sum_squares(X - np.sum([D[:,j]@L[j,:].reshape(1,no_samples) \n",
    "                                                           for j in range(k) if i!=i]) + Di@L[i,:].reshape(1,no_samples)))\n",
    "                                                 # cp.Minimize(np.linalg.norm(X - Dx@Lx, \"fro\"))\n",
    "        \n",
    "        constraints = [cp.norm2(Di) <= 1]\n",
    "\n",
    "        prob = cp.Problem(objective, constraints) \n",
    "        # try:\n",
    "        prob.solve(solver='OSQP',verbose=True)\n",
    "        # except cp.error.SolverError:\n",
    "        #     prob.solve(solver='SCS')\n",
    "\n",
    "        print(prob.status) #infea/sible_inaccurate\n",
    "        D[:,i] = Di.value.reshape(n,) #AttributeError: 'NoneType' object has no attribute 'reshape'\n",
    "\n",
    "    return D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\MySoftware\\python3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X = np.random.rand(150, 500)\n",
    "Dx_init = initialize_dictionary(X, 25)\n",
    "Lx = initialize_coefficients(Dx_init, X, 0.8)\n",
    "n = 150\n",
    "no_samples=500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================\n",
      "                                     CVXPY                                     \n",
      "                                     v1.3.1                                    \n",
      "===============================================================================\n",
      "(CVXPY) Jun 23 01:48:17 AM: Your problem has 150 variables, 1 constraints, and 0 parameters.\n",
      "(CVXPY) Jun 23 01:48:17 AM: It is compliant with the following grammars: DCP, DQCP\n",
      "(CVXPY) Jun 23 01:48:17 AM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n",
      "(CVXPY) Jun 23 01:48:17 AM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n"
     ]
    },
    {
     "ename": "SolverError",
     "evalue": "Problem could not be reduced to a QP, and no conic solvers exist among candidate solvers ({'qp_solvers': ['OSQP'], 'conic_solvers': []}).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSolverError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m D_new \u001b[39m=\u001b[39m update_dictionaries_step(X, Dx_init, Lx, n, no_samples)\n",
      "Cell \u001b[1;32mIn[16], line 15\u001b[0m, in \u001b[0;36mupdate_dictionaries_step\u001b[1;34m(X, D, L, n, no_samples)\u001b[0m\n\u001b[0;32m     13\u001b[0m prob \u001b[39m=\u001b[39m cp\u001b[39m.\u001b[39mProblem(objective, constraints) \n\u001b[0;32m     14\u001b[0m \u001b[39m# try:\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m prob\u001b[39m.\u001b[39;49msolve(solver\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mOSQP\u001b[39;49m\u001b[39m'\u001b[39;49m,verbose\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m     16\u001b[0m \u001b[39m# except cp.error.SolverError:\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[39m#     prob.solve(solver='SCS')\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[39mprint\u001b[39m(prob\u001b[39m.\u001b[39mstatus) \u001b[39m#infea/sible_inaccurate\u001b[39;00m\n",
      "File \u001b[1;32mc:\\MySoftware\\python3\\Lib\\site-packages\\cvxpy\\problems\\problem.py:493\u001b[0m, in \u001b[0;36mProblem.solve\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    491\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    492\u001b[0m     solve_func \u001b[39m=\u001b[39m Problem\u001b[39m.\u001b[39m_solve\n\u001b[1;32m--> 493\u001b[0m \u001b[39mreturn\u001b[39;00m solve_func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\MySoftware\\python3\\Lib\\site-packages\\cvxpy\\problems\\problem.py:1054\u001b[0m, in \u001b[0;36mProblem._solve\u001b[1;34m(self, solver, warm_start, verbose, gp, qcp, requires_grad, enforce_dpp, ignore_dpp, canon_backend, **kwargs)\u001b[0m\n\u001b[0;32m   1051\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munpack(chain\u001b[39m.\u001b[39mretrieve(soln))\n\u001b[0;32m   1052\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalue\n\u001b[1;32m-> 1054\u001b[0m data, solving_chain, inverse_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_problem_data(\n\u001b[0;32m   1055\u001b[0m     solver, gp, enforce_dpp, ignore_dpp, verbose, canon_backend, kwargs\n\u001b[0;32m   1056\u001b[0m )\n\u001b[0;32m   1058\u001b[0m \u001b[39mif\u001b[39;00m verbose:\n\u001b[0;32m   1059\u001b[0m     \u001b[39mprint\u001b[39m(_NUM_SOLVER_STR)\n",
      "File \u001b[1;32mc:\\MySoftware\\python3\\Lib\\site-packages\\cvxpy\\problems\\problem.py:631\u001b[0m, in \u001b[0;36mProblem.get_problem_data\u001b[1;34m(self, solver, gp, enforce_dpp, ignore_dpp, verbose, canon_backend, solver_opts)\u001b[0m\n\u001b[0;32m    629\u001b[0m \u001b[39mif\u001b[39;00m key \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cache\u001b[39m.\u001b[39mkey:\n\u001b[0;32m    630\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cache\u001b[39m.\u001b[39minvalidate()\n\u001b[1;32m--> 631\u001b[0m     solving_chain \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_construct_chain(\n\u001b[0;32m    632\u001b[0m         solver\u001b[39m=\u001b[39;49msolver, gp\u001b[39m=\u001b[39;49mgp,\n\u001b[0;32m    633\u001b[0m         enforce_dpp\u001b[39m=\u001b[39;49menforce_dpp,\n\u001b[0;32m    634\u001b[0m         ignore_dpp\u001b[39m=\u001b[39;49mignore_dpp,\n\u001b[0;32m    635\u001b[0m         canon_backend\u001b[39m=\u001b[39;49mcanon_backend,\n\u001b[0;32m    636\u001b[0m         solver_opts\u001b[39m=\u001b[39;49msolver_opts)\n\u001b[0;32m    637\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cache\u001b[39m.\u001b[39mkey \u001b[39m=\u001b[39m key\n\u001b[0;32m    638\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cache\u001b[39m.\u001b[39msolving_chain \u001b[39m=\u001b[39m solving_chain\n",
      "File \u001b[1;32mc:\\MySoftware\\python3\\Lib\\site-packages\\cvxpy\\problems\\problem.py:883\u001b[0m, in \u001b[0;36mProblem._construct_chain\u001b[1;34m(self, solver, gp, enforce_dpp, ignore_dpp, canon_backend, solver_opts)\u001b[0m\n\u001b[0;32m    881\u001b[0m candidate_solvers \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_find_candidate_solvers(solver\u001b[39m=\u001b[39msolver, gp\u001b[39m=\u001b[39mgp)\n\u001b[0;32m    882\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sort_candidate_solvers(candidate_solvers)\n\u001b[1;32m--> 883\u001b[0m \u001b[39mreturn\u001b[39;00m construct_solving_chain(\u001b[39mself\u001b[39;49m, candidate_solvers, gp\u001b[39m=\u001b[39;49mgp,\n\u001b[0;32m    884\u001b[0m                                enforce_dpp\u001b[39m=\u001b[39;49menforce_dpp,\n\u001b[0;32m    885\u001b[0m                                ignore_dpp\u001b[39m=\u001b[39;49mignore_dpp,\n\u001b[0;32m    886\u001b[0m                                canon_backend\u001b[39m=\u001b[39;49mcanon_backend,\n\u001b[0;32m    887\u001b[0m                                solver_opts\u001b[39m=\u001b[39;49msolver_opts)\n",
      "File \u001b[1;32mc:\\MySoftware\\python3\\Lib\\site-packages\\cvxpy\\reductions\\solvers\\solving_chain.py:184\u001b[0m, in \u001b[0;36mconstruct_solving_chain\u001b[1;34m(problem, candidates, gp, enforce_dpp, ignore_dpp, canon_backend, solver_opts)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(problem\u001b[39m.\u001b[39mvariables()) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    183\u001b[0m     \u001b[39mreturn\u001b[39;00m SolvingChain(reductions\u001b[39m=\u001b[39m[ConstantSolver()])\n\u001b[1;32m--> 184\u001b[0m reductions \u001b[39m=\u001b[39m _reductions_for_problem_class(problem, candidates, gp, solver_opts)\n\u001b[0;32m    186\u001b[0m \u001b[39m# Process DPP status of the problem.\u001b[39;00m\n\u001b[0;32m    187\u001b[0m dpp_context \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mdcp\u001b[39m\u001b[39m'\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m gp \u001b[39melse\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mdgp\u001b[39m\u001b[39m'\u001b[39m\n",
      "File \u001b[1;32mc:\\MySoftware\\python3\\Lib\\site-packages\\cvxpy\\reductions\\solvers\\solving_chain.py:124\u001b[0m, in \u001b[0;36m_reductions_for_problem_class\u001b[1;34m(problem, candidates, gp, solver_opts)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    122\u001b[0m     \u001b[39m# Canonicalize it to conic problem.\u001b[39;00m\n\u001b[0;32m    123\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m candidates[\u001b[39m'\u001b[39m\u001b[39mconic_solvers\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[1;32m--> 124\u001b[0m         \u001b[39mraise\u001b[39;00m SolverError(\u001b[39m\"\u001b[39m\u001b[39mProblem could not be reduced to a QP, and no \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    125\u001b[0m                           \u001b[39m\"\u001b[39m\u001b[39mconic solvers exist among candidate solvers \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    126\u001b[0m                           \u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m).\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m candidates)\n\u001b[0;32m    128\u001b[0m constr_types \u001b[39m=\u001b[39m {\u001b[39mtype\u001b[39m(c) \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m problem\u001b[39m.\u001b[39mconstraints}\n\u001b[0;32m    129\u001b[0m \u001b[39mif\u001b[39;00m FiniteSet \u001b[39min\u001b[39;00m constr_types:\n",
      "\u001b[1;31mSolverError\u001b[0m: Problem could not be reduced to a QP, and no conic solvers exist among candidate solvers ({'qp_solvers': ['OSQP'], 'conic_solvers': []})."
     ]
    }
   ],
   "source": [
    "D_new = update_dictionaries_step(X, Dx_init, Lx, n, no_samples)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\MySoftware\\python3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans \n",
    "\n",
    "W = np.random.uniform(0,1, [645, 500])\n",
    "Dw = initialize_dictionary(W, 25)\n",
    "Lx = np.random.uniform(0,1, [25, 500])\n",
    "M = np.random.uniform(0,1, [25, 25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from sklearn.linear_model import LassoLars\n",
    " \n",
    "\n",
    "def lars_col_by_col(X, y , alpha=0.01):\n",
    "    lasso = LassoLars(alpha=alpha)\n",
    "    lasso.fit(X, y)\n",
    "    return lasso.coef_\n",
    "\n",
    "\n",
    "def update_Lw_step(W, Dw, M, Lx, gamma=0.7, alpha=0.01):\n",
    "\n",
    "    Y = np.vstack([W, gamma * M @ Lx])\n",
    "    X = np.vstack([Dw, gamma * np.identity(25)])\n",
    "    Lw = np.zeros([Dw.shape[1], W.shape[1]])\n",
    "    \n",
    "    for i, y in enumerate(Y.T):\n",
    "    \n",
    "        lw_col = lars_col_by_col(X, y)\n",
    "        Lw[:, i] = lw_col\n",
    "\n",
    "    return Lw\n",
    "\n",
    "Lw = update_Lw_step(W, Dw, M, Lx, gamma=0.7, alpha=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
